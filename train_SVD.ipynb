{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15150737\n",
      "14161837\n",
      "Top recommended movies: ['whiplash-2014', 'saltburn', 'the-menu-2022', 'oppenheimer-2023', 'barbie', 'black-swan', 'interstellar', 'fight-club', 'la-la-land', 'scream']\n",
      "Top recommended movies: ['the-dark-knight', 'everything-everywhere-all-at-once', 'parasite-2019', 'whiplash-2014', 'spider-man-into-the-spider-verse', 'mission-impossible-fallout', 'top-gun-maverick', 'arrival-2016', 'inglourious-basterds', 'the-batman']\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Connect to your SQLite database\n",
    "conn = sqlite3.connect('my_letterboxd_data.db')\n",
    "\n",
    "# Load ratings data\n",
    "query = \"\"\"\n",
    "SELECT username, movie_name, rating\n",
    "FROM users\n",
    "\"\"\"\n",
    "ratings_df = pd.read_sql(query, conn)\n",
    "ratings_df.dropna(subset=['rating'], inplace=True)\n",
    "ratings_df['rating'] = ratings_df['rating'].astype(float)\n",
    "ratings_df['username'] = ratings_df['username'].astype(str)\n",
    "ratings_df['movie_name'] = ratings_df['movie_name'].astype(str)\n",
    "\n",
    "query_movie_details = \"\"\"\n",
    "SELECT letterboxd_slug, movie_name, director, actors, genres\n",
    "FROM film_details_small\n",
    "\"\"\"\n",
    "movie_details_df = pd.read_sql(query_movie_details, conn)\n",
    "\n",
    "\n",
    "# Example of filtering out movies and users with fewer than a certain number of ratings\n",
    "min_movie_ratings = 25 # Movies with fewer than 10 ratings\n",
    "min_user_ratings = 50 # Users with fewer than 5 ratings\n",
    "print(len(ratings_df))\n",
    "filtered_ratings = ratings_df.groupby('movie_name').filter(lambda x: len(x) >= min_movie_ratings)\n",
    "filtered_ratings = filtered_ratings.groupby('username').filter(lambda x: len(x) >= min_user_ratings)\n",
    "# print('hello')\n",
    "# Proceed with the filtered_ratings DataFrame\n",
    "ratings_df = filtered_ratings\n",
    "print(len(ratings_df))\n",
    "conn.close()\n",
    "\n",
    "# split the data into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train test split usernames\n",
    "train_users, test_users = train_test_split(ratings_df['username'].unique(), test_size=0.2, random_state=42)\n",
    "\n",
    "# split the data into training and testing\n",
    "test_data = ratings_df[ratings_df['username'].isin(test_users)]\n",
    "ratings_df = ratings_df[ratings_df['username'].isin(train_users)]\n",
    "\n",
    "\n",
    "\n",
    "# Create a user-movie ratings matrix\n",
    "user_movie_ratings = ratings_df.pivot_table(index='username', columns='movie_name', values='rating').fillna(0)\n",
    "\n",
    "# Convert to sparse matrix\n",
    "ratings_matrix = csr_matrix(user_movie_ratings.values)\n",
    "\n",
    "# Apply SVD\n",
    "svd = TruncatedSVD(n_components=20) # You can adjust the number of components\n",
    "matrix_reduced = svd.fit_transform(ratings_matrix)\n",
    "\n",
    "# Compute similarity scores\n",
    "user_similarity = cosine_similarity(matrix_reduced)\n",
    "\n",
    "def predict_top_movies(user_index, top_k=10):\n",
    "    similarity_scores = list(enumerate(user_similarity[user_index]))\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "    top_users_indices = [i[0] for i in similarity_scores[1:top_k+1]] # Skip self\n",
    "    top_users_ratings = user_movie_ratings.iloc[top_users_indices].mean(axis=0)\n",
    "    recommended_movies = top_users_ratings.sort_values(ascending=False).index.tolist()\n",
    "    return recommended_movies[:top_k]\n",
    "\n",
    "# Example usage\n",
    "user_index = 0 # Assuming you want recommendations for the first user in the dataset\n",
    "top_movies = predict_top_movies(user_index, top_k=10)\n",
    "print(f\"Top recommended movies: {top_movies}\")\n",
    "\n",
    "\n",
    "# print top predicted movies for specific user\n",
    "user_index = user_movie_ratings.index.get_loc('nconterno')\n",
    "top_movies = predict_top_movies(user_index, top_k=10)\n",
    "print(f\"Top recommended movies: {top_movies}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('my_letterboxd_data.db')\n",
    "query_movie_details = \"\"\"\n",
    "SELECT letterboxd_slug, movie_name, director, actors, genres\n",
    "FROM film_details_small\n",
    "\"\"\"\n",
    "movie_details_df = pd.read_sql(query_movie_details, conn)\n",
    "conn.close()\n",
    "\n",
    "#rename movie_name to  real_movie_name\n",
    "movie_details_df.rename(columns={'movie_name': 'real_movie_name'}, inplace=True)\n",
    "# rename letterboxd_slug to movie_name\n",
    "movie_details_df.rename(columns={'letterboxd_slug': 'movie_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ayoo\n",
      "ayoo2\n",
      "Top recommended movies: movie_name\n",
      "the-lord-of-the-rings-2003         9.454545\n",
      "a-brighter-summer-day              9.375000\n",
      "the-godfather-part-ii              9.374046\n",
      "chernobyl                          9.275229\n",
      "mishima-a-life-in-four-chapters    9.263158\n",
      "                                     ...   \n",
      "short-cuts                         8.555556\n",
      "a-man-escaped                      8.550000\n",
      "three-colours-red                  8.545455\n",
      "the-iron-giant                     8.542029\n",
      "sunset-boulevard                   8.538922\n",
      "Length: 100, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def predict_top_movies(user_index, top_k=10):\n",
    "    # Compute similarity scores with other users\n",
    "    similarity_scores = list(enumerate(user_similarity[user_index]))\n",
    "    # Sort users by similarity score in descending order (most similar first)\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get indices of top_k similar users (excluding the user itself which is at index 0)\n",
    "    top_users_indices = []\n",
    "    for i in (range(1, 1000)):  # Considering top 999 similar users after excluding the user itself\n",
    "        top_users_indices.append(similarity_scores[i][0])\n",
    "    \n",
    "    # Select the ratings of these top users\n",
    "    top_users_ratings = user_movie_ratings.iloc[top_users_indices]\n",
    "\n",
    "    # Filter movies where less than 5 users rated it (non-zero ratings)\n",
    "    valid_movies = top_users_ratings.apply(lambda x: x > 0).sum(axis=0) >= 5\n",
    "    top_users_ratings = top_users_ratings.loc[:, valid_movies]\n",
    "\n",
    "    # Calculate the mean of ratings, ignoring zeros\n",
    "    recommended_movies = top_users_ratings.apply(lambda x: np.mean(x[x > 0]), axis=0)\n",
    "\n",
    "    # remove movies not in the movie_details_df\n",
    "    recommended_movies = recommended_movies[recommended_movies.index.isin(movie_details_df['movie_name'])]\n",
    "    print('ayoo')\n",
    "    # remove movies that are documentaries\n",
    "    recommended_movies = recommended_movies[~recommended_movies.index.isin(movie_details_df[movie_details_df['genres'].str.contains('Documentary')]['movie_name'])]\n",
    "\n",
    "    print('ayoo2')\n",
    "\n",
    "    # remove movies the user has already rated\n",
    "    user_rated_movies = user_movie_ratings.iloc[user_index]\n",
    "    recommended_movies = recommended_movies[~recommended_movies.index.isin(user_rated_movies[user_rated_movies > 0].index)]\n",
    "\n",
    "    # Sort the average ratings in descending order and select the top_k movies\n",
    "    recommended_movies = recommended_movies.sort_values(ascending=False)\n",
    "    return recommended_movies[:top_k]\n",
    "\n",
    "# Example usage\n",
    "user_index = user_movie_ratings.index.get_loc('nconterno')\n",
    "top_movies = predict_top_movies(user_index, top_k=100)\n",
    "print(f\"Top recommended movies: {top_movies}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2800736, 3)\n",
      "ayoo\n",
      "ayoo2\n",
      "Top recommended movies for new user: movie_name\n",
      "the-lord-of-the-rings-2003             9.695652\n",
      "the-red-shoes                          9.600000\n",
      "high-and-low                           9.583333\n",
      "the-holy-mountain                      9.500000\n",
      "the-godfather-part-ii                  9.418605\n",
      "                                         ...   \n",
      "pink-floyd-the-wall                    8.733333\n",
      "the-last-black-man-in-san-francisco    8.733333\n",
      "sympathy-for-mr-vengeance              8.714286\n",
      "midnight-cowboy                        8.714286\n",
      "drive-my-car                           8.714286\n",
      "Length: 100, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def predict_movies_for_new_user(new_user_ratings, top_k=10):\n",
    "    # Integrate new user ratings into the existing user-movie matrix\n",
    "    # Create a Series from the new user ratings, reindexing to match the columns of the existing matrix\n",
    "    new_user_series = pd.Series(new_user_ratings).reindex(user_movie_ratings.columns).fillna(0)\n",
    "    \n",
    "    # Append this user to the existing matrix and transform using the existing SVD model\n",
    "    new_user_vector = svd.transform(csr_matrix(new_user_series.values.reshape(1, -1)))\n",
    "\n",
    "    # Compute cosine similarity between this new user and all other users\n",
    "    new_user_similarity = cosine_similarity(new_user_vector, matrix_reduced).flatten()\n",
    "\n",
    "    # Exclude the new user's self-comparison and get indices of top similar users\n",
    "    top_users_indices = np.argsort(-new_user_similarity)[1:1000]\n",
    "    top_users_ratings = user_movie_ratings.iloc[top_users_indices]\n",
    "\n",
    "    # Filter movies where less than 5 users rated it (non-zero ratings)\n",
    "    valid_movies = top_users_ratings.apply(lambda x: x > 0).sum(axis=0) >= 5\n",
    "    top_users_ratings = top_users_ratings.loc[:, valid_movies]\n",
    "\n",
    "    # Calculate the mean of ratings, ignoring zeros\n",
    "    recommended_movies = top_users_ratings.apply(lambda x: np.mean(x[x > 0]), axis=0)\n",
    "\n",
    "    # remove movies not in the movie_details_df\n",
    "    recommended_movies = recommended_movies[recommended_movies.index.isin(movie_details_df['movie_name'])]\n",
    "    print('ayoo')\n",
    "    # remove movies that are documentaries\n",
    "    recommended_movies = recommended_movies[~recommended_movies.index.isin(movie_details_df[movie_details_df['genres'].str.contains('Documentary')]['movie_name'])]\n",
    "\n",
    "    print('ayoo2')\n",
    "\n",
    "    # remove movies the user has already rated\n",
    "    user_rated_movies = user_movie_ratings.iloc[user_index]\n",
    "    # recommended_movies = recommended_movies[~recommended_movies.index.isin(user_rated_movies[user_rated_movies > 0].index)]\n",
    "\n",
    "    # Sort the average ratings in descending order and select the top_k movies\n",
    "    recommended_movies = recommended_movies.sort_values(ascending=False)\n",
    "    return recommended_movies[:top_k]\n",
    "\n",
    "\n",
    "print(test_data.shape)\n",
    "test_user_movie_ratings = test_data.pivot_table(index='username', columns='movie_name', values='rating').fillna(0)\n",
    "# example usage from random user from test data\n",
    "test_user = test_user_movie_ratings.index[0]\n",
    "test_user_ratings = test_user_movie_ratings.loc[test_user]\n",
    "top_movies = predict_movies_for_new_user(test_user_ratings, top_k=100)\n",
    "print(f\"Top recommended movies for new user: {top_movies}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ayoo\n",
      "ayoo2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:11<01:46, 11.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ayoo\n",
      "ayoo2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:23<01:34, 11.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ayoo\n",
      "ayoo2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:35<01:22, 11.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ayoo\n",
      "ayoo2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:46<01:09, 11.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ayoo\n",
      "ayoo2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:59<00:59, 11.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ayoo\n",
      "ayoo2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [01:10<00:47, 11.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ayoo\n",
      "ayoo2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [01:22<00:35, 11.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ayoo\n",
      "ayoo2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [01:34<00:23, 11.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ayoo\n",
      "ayoo2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [01:46<00:11, 11.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ayoo\n",
      "ayoo2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:57<00:00, 11.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.5586850577266351\n",
      "Mean Squared Error: 3.828424482103301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# using the test data to evaluate the model using MAE and MSE and predict_movies_for_new_user\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# for 100 users in the test data\n",
    "mae = []\n",
    "mse = []\n",
    "# unique movies in the test data\n",
    "unique_movies = test_data['movie_name'].unique()\n",
    "for i in tqdm(range(10)):\n",
    "    test_user = test_user_movie_ratings.index[i]\n",
    "    test_user_ratings = test_user_movie_ratings.loc[test_user]\n",
    "    top_movies = predict_movies_for_new_user(test_user_ratings, top_k=len(unique_movies))\n",
    "    # get error for the user\n",
    "    for movie in test_user_ratings.index:\n",
    "        if movie in top_movies.index:\n",
    "            mae.append(mean_absolute_error([test_user_ratings[movie]], [top_movies[movie]]))\n",
    "            mse.append(mean_squared_error([test_user_ratings[movie]], [top_movies[movie]]))\n",
    "        else:\n",
    "            mae.append(mean_absolute_error([test_user_ratings[movie]], [0]))\n",
    "            mse.append(mean_squared_error([test_user_ratings[movie]], [0]))\n",
    "\n",
    "print(f\"Mean Absolute Error: {np.mean(mae)}\")\n",
    "print(f\"Mean Squared Error: {np.mean(mse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended movies for 0000_q: movie_name\n",
      "la-la-land                                5.504\n",
      "black-swan                                5.208\n",
      "little-women-2019                         5.026\n",
      "whiplash-2014                             4.970\n",
      "the-perks-of-being-a-wallflower           4.872\n",
      "                                          ...  \n",
      "black-mirror-the-entire-history-of-you    0.608\n",
      "green-book                                0.608\n",
      "marley-me                                 0.608\n",
      "okja                                      0.608\n",
      "life-is-beautiful                         0.608\n",
      "Length: 500, dtype: float64\n",
      "Index(['0000_q', '004lio', '03_sats', '04danysolodany', '0511milou', '058218',\n",
      "       '0714c', '098km', '09plutos', '0elle'],\n",
      "      dtype='object', name='username')\n"
     ]
    }
   ],
   "source": [
    "def predict_top_movies_with_ratings_by_username(username, top_k=10):\n",
    "    if username not in user_movie_ratings.index:\n",
    "        return \"No data available for user: {}\".format(username)\n",
    "    \n",
    "    # Find user index\n",
    "    user_index = user_movie_ratings.index.get_loc(username)\n",
    "    \n",
    "    # Compute similarity scores for the specified user\n",
    "    similarity_scores = list(enumerate(user_similarity[user_index]))\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get indices of top similar users excluding the user themselves\n",
    "    top_users_indices = [i[0] for i in similarity_scores[1:top_k+1]]\n",
    "    \n",
    "    # Aggregate the ratings of these top similar users\n",
    "    top_users_ratings = user_movie_ratings.iloc[top_users_indices].mean(axis=0)\n",
    "    \n",
    "    # Filter out movies the user has already seen\n",
    "    movies_already_seen = user_movie_ratings.loc[username, user_movie_ratings.loc[username,:] > 0].index\n",
    "    top_users_ratings_filtered = top_users_ratings.drop(movies_already_seen)\n",
    "    \n",
    "    # Sort the movies based on predicted ratings and return the top k\n",
    "    recommended_movies_and_ratings = top_users_ratings_filtered.sort_values(ascending=False).head(top_k)\n",
    "    return recommended_movies_and_ratings\n",
    "\n",
    "# Example usage\n",
    "username = '0000_q'\n",
    "top_movies = predict_top_movies_with_ratings_by_username(username, top_k=500)\n",
    "print(f\"Top recommended movies for {username}: {top_movies}\")\n",
    "\n",
    "# print out first 10 usernames\n",
    "print(user_movie_ratings.index[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m             mse \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (predicted_rating \u001b[39m-\u001b[39m rating) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m     13\u001b[0m     \u001b[39mreturn\u001b[39;00m mse \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(test_data)\n\u001b[0;32m---> 15\u001b[0m \u001b[39mprint\u001b[39m(mse(test_data))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_data' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended movies for nconterno: movie_name\n",
      "parasite-2019                                       5.079031\n",
      "spider-man-across-the-spider-verse                  4.253642\n",
      "joker-2019                                          4.202354\n",
      "the-wolf-of-wall-street                             3.702604\n",
      "eternal-sunshine-of-the-spotless-mind               3.484730\n",
      "kill-bill-vol-1                                     3.421067\n",
      "guardians-of-the-galaxy                             3.385413\n",
      "ratatouille                                         3.371113\n",
      "the-matrix                                          3.312844\n",
      "goodfellas                                          3.303334\n",
      "shutter-island                                      3.277741\n",
      "top-gun-maverick                                    3.239517\n",
      "spirited-away                                       3.235921\n",
      "black-swan                                          3.226378\n",
      "the-lord-of-the-rings-the-fellowship-of-the-ring    3.217327\n",
      "arrival-2016                                        3.192973\n",
      "fantastic-mr-fox                                    3.156452\n",
      "blade-runner-2049                                   3.125995\n",
      "no-country-for-old-men                              3.078814\n",
      "mad-max-fury-road                                   3.054380\n",
      "home-alone                                          3.053765\n",
      "her                                                 3.048129\n",
      "killers-of-the-flower-moon                          3.043822\n",
      "batman-begins                                       2.976284\n",
      "saltburn                                            2.968274\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def predict_top_movies_with_ratings_by_username(username, top_k=10):\n",
    "    if username not in user_movie_ratings.index:\n",
    "        return \"No data available for user: {}\".format(username)\n",
    "    \n",
    "    # Compute aggregate ratings across all users, weighted by similarity\n",
    "    similarity_scores = user_similarity[user_movie_ratings.index.get_loc(username)]\n",
    "    weighted_ratings = user_movie_ratings.multiply(similarity_scores, axis=0)\n",
    "    aggregate_ratings = weighted_ratings.sum(axis=0) / similarity_scores.sum()\n",
    "    \n",
    "    # Filter out movies the user has already seen\n",
    "    movies_already_seen = user_movie_ratings.loc[username, user_movie_ratings.loc[username,:] > 0].index\n",
    "    aggregate_ratings_filtered = aggregate_ratings.drop(movies_already_seen)\n",
    "    \n",
    "    # Sort the movies based on predicted ratings and return the top k\n",
    "    recommended_movies_and_ratings = aggregate_ratings_filtered.sort_values(ascending=False).head(top_k)\n",
    "    return recommended_movies_and_ratings\n",
    "\n",
    "# Example usage\n",
    "username = 'nconterno'\n",
    "top_movies = predict_top_movies_with_ratings_by_username(username, top_k=25)\n",
    "print(f\"Top recommended movies for {username}: {top_movies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m t1, test_data \u001b[39m=\u001b[39m train_test_split(ratings_df, test_size\u001b[39m=\u001b[39m\u001b[39m0.05\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[39m# use for loop with tqdm to show progress\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m test_data[\u001b[39m'\u001b[39m\u001b[39mpredicted_rating\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [predict_rating(row[\u001b[39m'\u001b[39m\u001b[39musername\u001b[39m\u001b[39m'\u001b[39m], row[\u001b[39m'\u001b[39m\u001b[39mmovie_name\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39mfor\u001b[39;00m index, row \u001b[39min\u001b[39;00m tqdm(test_data\u001b[39m.\u001b[39miterrows(), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(test_data))]\n\u001b[1;32m     24\u001b[0m mse \u001b[39m=\u001b[39m ((test_data[\u001b[39m'\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m test_data[\u001b[39m'\u001b[39m\u001b[39mpredicted_rating\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mmean()\n\u001b[1;32m     25\u001b[0m mae \u001b[39m=\u001b[39m (test_data[\u001b[39m'\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m test_data[\u001b[39m'\u001b[39m\u001b[39mpredicted_rating\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mabs()\u001b[39m.\u001b[39mmean()\n",
      "Cell \u001b[0;32mIn[12], line 23\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     20\u001b[0m t1, test_data \u001b[39m=\u001b[39m train_test_split(ratings_df, test_size\u001b[39m=\u001b[39m\u001b[39m0.05\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[39m# use for loop with tqdm to show progress\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m test_data[\u001b[39m'\u001b[39m\u001b[39mpredicted_rating\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [predict_rating(row[\u001b[39m'\u001b[39;49m\u001b[39musername\u001b[39;49m\u001b[39m'\u001b[39;49m], row[\u001b[39m'\u001b[39;49m\u001b[39mmovie_name\u001b[39;49m\u001b[39m'\u001b[39;49m]) \u001b[39mfor\u001b[39;00m index, row \u001b[39min\u001b[39;00m tqdm(test_data\u001b[39m.\u001b[39miterrows(), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(test_data))]\n\u001b[1;32m     24\u001b[0m mse \u001b[39m=\u001b[39m ((test_data[\u001b[39m'\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m test_data[\u001b[39m'\u001b[39m\u001b[39mpredicted_rating\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mmean()\n\u001b[1;32m     25\u001b[0m mae \u001b[39m=\u001b[39m (test_data[\u001b[39m'\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m test_data[\u001b[39m'\u001b[39m\u001b[39mpredicted_rating\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mabs()\u001b[39m.\u001b[39mmean()\n",
      "Cell \u001b[0;32mIn[12], line 11\u001b[0m, in \u001b[0;36mpredict_rating\u001b[0;34m(username, movie_name)\u001b[0m\n\u001b[1;32m      8\u001b[0m similarity_scores \u001b[39m=\u001b[39m user_similarity[user_index]\n\u001b[1;32m      9\u001b[0m ratings \u001b[39m=\u001b[39m user_movie_ratings[movie_name]\n\u001b[0;32m---> 11\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39;49msum(similarity_scores) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     12\u001b[0m     \u001b[39mreturn\u001b[39;00m user_movie_ratings[movie_name]\u001b[39m.\u001b[39mmean()  \u001b[39m# Fallback to movie average\u001b[39;00m\n\u001b[1;32m     13\u001b[0m predicted_rating \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(similarity_scores, ratings) \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39msum(similarity_scores)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/core/fromnumeric.py:2313\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2310\u001b[0m         \u001b[39mreturn\u001b[39;00m out\n\u001b[1;32m   2311\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[0;32m-> 2313\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49madd, \u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, dtype, out, keepdims\u001b[39m=\u001b[39;49mkeepdims,\n\u001b[1;32m   2314\u001b[0m                       initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/core/fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 88\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39;49mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "# get mse for the test data\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "def predict_rating(username, movie_name):\n",
    "    try:\n",
    "        user_index = user_movie_ratings.index.get_loc(username)\n",
    "        movie_index = user_movie_ratings.columns.get_loc(movie_name)\n",
    "        similarity_scores = user_similarity[user_index]\n",
    "        ratings = user_movie_ratings[movie_name]\n",
    "        \n",
    "        if np.sum(similarity_scores) != 0:\n",
    "            return user_movie_ratings[movie_name].mean()  # Fallback to movie average\n",
    "        predicted_rating = np.dot(similarity_scores, ratings) / np.sum(similarity_scores)\n",
    "        return predicted_rating\n",
    "    except KeyError:\n",
    "        return ratings_df['rating'].mean()  # Fallback to global average if movie or user not found\n",
    "\n",
    "#train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "t1, test_data = train_test_split(ratings_df, test_size=0.05)\n",
    "\n",
    "# use for loop with tqdm to show progress\n",
    "test_data['predicted_rating'] = [predict_rating(row['username'], row['movie_name']) for index, row in tqdm(test_data.iterrows(), total=len(test_data))]\n",
    "mse = ((test_data['rating'] - test_data['predicted_rating'])**2).mean()\n",
    "mae = (test_data['rating'] - test_data['predicted_rating']).abs().mean()\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\nSELECT movie_name, genre, director, release_year FROM movies\n': no such table: movies",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/sql.py:2262\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2261\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2262\u001b[0m     cur\u001b[39m.\u001b[39;49mexecute(sql, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m   2263\u001b[0m     \u001b[39mreturn\u001b[39;00m cur\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: movies",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 30\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39m# Load additional movie information\u001b[39;00m\n\u001b[1;32m     27\u001b[0m query_movie_info \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[39mSELECT movie_name, genre, director, release_year FROM movies\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m---> 30\u001b[0m movies_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_sql(query_movie_info, conn)\n\u001b[1;32m     32\u001b[0m \u001b[39m# Merge the ratings with the movie information\u001b[39;00m\n\u001b[1;32m     33\u001b[0m full_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(ratings_df, movies_df, on\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmovie_name\u001b[39m\u001b[39m\"\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/sql.py:654\u001b[0m, in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[39mwith\u001b[39;00m pandasSQL_builder(con) \u001b[39mas\u001b[39;00m pandas_sql:\n\u001b[1;32m    653\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[0;32m--> 654\u001b[0m         \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39;49mread_query(\n\u001b[1;32m    655\u001b[0m             sql,\n\u001b[1;32m    656\u001b[0m             index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[1;32m    657\u001b[0m             params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    658\u001b[0m             coerce_float\u001b[39m=\u001b[39;49mcoerce_float,\n\u001b[1;32m    659\u001b[0m             parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[1;32m    660\u001b[0m             chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m    661\u001b[0m             dtype_backend\u001b[39m=\u001b[39;49mdtype_backend,\n\u001b[1;32m    662\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    663\u001b[0m         )\n\u001b[1;32m    665\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    666\u001b[0m         _is_table_name \u001b[39m=\u001b[39m pandas_sql\u001b[39m.\u001b[39mhas_table(sql)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/sql.py:2326\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m   2315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_query\u001b[39m(\n\u001b[1;32m   2316\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   2317\u001b[0m     sql,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2324\u001b[0m     dtype_backend: DtypeBackend \u001b[39m|\u001b[39m Literal[\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2325\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Iterator[DataFrame]:\n\u001b[0;32m-> 2326\u001b[0m     cursor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(sql, params)\n\u001b[1;32m   2327\u001b[0m     columns \u001b[39m=\u001b[39m [col_desc[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m col_desc \u001b[39min\u001b[39;00m cursor\u001b[39m.\u001b[39mdescription]\n\u001b[1;32m   2329\u001b[0m     \u001b[39mif\u001b[39;00m chunksize \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/sql.py:2274\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2271\u001b[0m     \u001b[39mraise\u001b[39;00m ex \u001b[39mfrom\u001b[39;00m \u001b[39minner_exc\u001b[39;00m\n\u001b[1;32m   2273\u001b[0m ex \u001b[39m=\u001b[39m DatabaseError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExecution failed on sql \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00msql\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mexc\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2274\u001b[0m \u001b[39mraise\u001b[39;00m ex \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql '\nSELECT movie_name, genre, director, release_year FROM movies\n': no such table: movies"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "# Assuming you've already loaded 'ratings_df' as shown in the previous code\n",
    "# Connect to your SQLite database\n",
    "conn = sqlite3.connect('my_letterboxd_data.db')\n",
    "\n",
    "# Load ratings data\n",
    "query = \"\"\"\n",
    "SELECT username, movie_name, rating\n",
    "FROM users\n",
    "\"\"\"\n",
    "ratings_df = pd.read_sql(query, conn)\n",
    "ratings_df.dropna(subset=['rating'], inplace=True)\n",
    "ratings_df['rating'] = ratings_df['rating'].astype(float)\n",
    "ratings_df['username'] = ratings_df['username'].astype(str)\n",
    "ratings_df['movie_name'] = ratings_df['movie_name'].astype(str)\n",
    "\n",
    "unique_user_ids = ratings_df['username'].unique()\n",
    "unique_movie_titles = ratings_df['movie_name'].unique()\n",
    "\n",
    "embedding_dimension = 128\n",
    "# Load additional movie information\n",
    "query_movie_info = \"\"\"\n",
    "SELECT movie_name, genre, director, release_year FROM movies\n",
    "\"\"\"\n",
    "movies_df = pd.read_sql(query_movie_info, conn)\n",
    "\n",
    "# Merge the ratings with the movie information\n",
    "full_df = pd.merge(ratings_df, movies_df, on=\"movie_name\", how=\"left\")\n",
    "\n",
    "# Process categorical data and normalize numerical data as needed\n",
    "# This step will depend on your specific dataset and features\n",
    "class MovieRecommendationModel(tfrs.Model):\n",
    "    def __init__(self, user_model, movie_model, task):\n",
    "        super().__init__()\n",
    "        self.movie_model: tf.keras.Model = movie_model\n",
    "        self.user_model: tf.keras.Model = user_model\n",
    "        self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "        return self.task(user_embeddings, movie_embeddings)\n",
    "\n",
    "# Define the model components\n",
    "user_model = tf.keras.Sequential([\n",
    "    layers.StringLookup(\n",
    "        vocabulary=unique_user_ids, mask_token=None),\n",
    "    # Add more layers as needed\n",
    "    layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "])\n",
    "\n",
    "movie_model = tf.keras.Sequential([\n",
    "    layers.StringLookup(\n",
    "        vocabulary=unique_movie_titles, mask_token=None),\n",
    "    layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension),\n",
    "    # Add layers for processing movie metadata\n",
    "])\n",
    "\n",
    "task = tfrs.tasks.Ranking(\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MovieRecommendationModel(user_model, movie_model, task)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "# Assuming you have a dataset ready\n",
    "# Convert 'full_df' to a TensorFlow dataset and split into train and test sets\n",
    "\n",
    "tf_dataset = tf.data.Dataset.from_tensor_slices({\n",
    "    \"user_id\": full_df[\"username\"].values,\n",
    "    \"movie_title\": full_df[\"movie_name\"].values,\n",
    "    # Include additional movie features here\n",
    "})\n",
    "tf_dataset = tf_dataset.batch(1024)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(tf_dataset, epochs=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
